# Word_level_RNN

• Implemented Backpropagation through time: In a vanilla RNN with a single hidden layer having three sets of weights: U, V, W. And using softmax units for the output layer and tanh units for the hidden layer. 
• Trained your recurrent neural network using the dataset created above. The learning parameters are (sequence length, learning rate, etc.).
• Reporting the training loss vs epochs as a plot.
• During training, chose 5 breakpoints (e.g., you train the network for 100 epochs and you choose the end of epoch 20, 40, 60, 80, 100) and show how well your network learns through time.
• Did it by feeding in the network a chunk of your training text and show what is the
output of the network. Also, reported about gradient check routine.
